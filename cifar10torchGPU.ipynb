{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPdl7sBaeuKOt6oDU2fFTnq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ngcthanh2903/pytorch/blob/main/cifar10torchGPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qypfIwICYrKF"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import cifar10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) =cifar10.load_data()\n",
        "print(x_test.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LAEjM7gZS9R",
        "outputId": "87a86e53-f4d9-46bd-db1e-764dcaf70914"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 8s 0us/step\n",
            "170508288/170498071 [==============================] - 8s 0us/step\n",
            "uint8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=x_train.reshape(-1,3,32,32)\n",
        "x_test=x_test.reshape(-1,3,32,32)\n"
      ],
      "metadata": {
        "id": "_OGWSIOvZsuW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seL4uDNpaZup",
        "outputId": "8b8368af-f53f-4708-ab47-2b545d2b7ab4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 3, 32, 32)\n",
            "(10000, 3, 32, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim.adam as adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import TensorDataset\n",
        "from torchsummary import summary\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "Vt8mn0h3alQf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.from_numpy(x_train)\n",
        "y_train = torch.from_numpy(y_train)\n",
        "x_test = torch.from_numpy(x_test)\n",
        "y_test = torch.from_numpy(y_test)\n",
        "x_train = x_train.to(torch.float32)\n",
        "x_test = x_test.to(torch.float32)"
      ],
      "metadata": {
        "id": "PkqEs0XscgVn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size =64\n",
        "train_ds = TensorDataset(x_train,y_train)\n",
        "test_ds = TensorDataset(x_test,y_test)\n",
        "train_dl = DataLoader(train_ds,batch_size,shuffle=True)\n",
        "test_dl = DataLoader(test_ds,batch_size,shuffle=True)"
      ],
      "metadata": {
        "id": "Im4d1ajZh5Vd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yR1BctsI6aUL",
        "outputId": "c30eef01-920e-4669-9982-4a8f0f1b3003"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3,padding=2)\n",
        "        self.conv2 = nn.Conv2d(32,64,kernel_size= 3,padding=2)\n",
        "        self.conv3 = nn.Conv2d(64,64,kernel_size=3,padding=2)\n",
        "        self.conv3_drop = nn.Dropout2d()\n",
        "        self.conv4 = nn.Conv2d(64,128,kernel_size=3,padding=2)\n",
        "        self.fc1 = nn.Linear(1152, 100)\n",
        "        self.fc2 = nn.Linear(100, 10)\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv3_drop(self.conv3(x)), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv4(x), 2))\n",
        "        #print(x.shape)\n",
        "        #print(x.reshape(x.shape[0],-1).shape)\n",
        "        x = x.view(-1, 1152)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x)"
      ],
      "metadata": {
        "id": "o59tizgciA_K"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "model = Net()\n",
        "model.cuda()\n",
        "\n",
        "summary(model, (3, 32, 32))\n",
        "loss_fn = CrossEntropyLoss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8GSanp5iLgS",
        "outputId": "7826b72e-9741-4e48-84dd-bd343e1697fd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 34, 34]             896\n",
            "            Conv2d-2           [-1, 64, 19, 19]          18,496\n",
            "            Conv2d-3           [-1, 64, 11, 11]          36,928\n",
            "         Dropout2d-4           [-1, 64, 11, 11]               0\n",
            "            Conv2d-5            [-1, 128, 7, 7]          73,856\n",
            "            Linear-6                  [-1, 100]         115,300\n",
            "            Linear-7                   [-1, 10]           1,010\n",
            "================================================================\n",
            "Total params: 246,486\n",
            "Trainable params: 246,486\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.63\n",
            "Params size (MB): 0.94\n",
            "Estimated Total Size (MB): 1.58\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential()\n",
        "model.add_module('conv1',nn.Conv2d(3,32,kernel_size=3,padding = 'same'))\n",
        "model.add_module('relu1',nn.ReLU())\n",
        "model.add_module('conv2',nn.Conv2d(32,32,kernel_size=3,padding='same'))\n",
        "model.add_module('relu2',nn.ReLU())\n",
        "model.add_module('pool1',nn.MaxPool2d(2))\n",
        "model.add_module('bn1',nn.BatchNorm2d(32))\n",
        "\n",
        "model.add_module('conv3',nn.Conv2d(32,64,kernel_size=3,padding = 'same'))\n",
        "model.add_module('relu3',nn.ReLU())\n",
        "model.add_module('conv4',nn.Conv2d(64,64,kernel_size=3,padding='same'))\n",
        "model.add_module('relu4',nn.ReLU())\n",
        "model.add_module('pool2',nn.MaxPool2d(2))\n",
        "model.add_module('bn2',nn.BatchNorm2d(64))\n",
        "\n",
        "model.add_module('conv5',nn.Conv2d(64,128,kernel_size=3,padding = 'same'))\n",
        "model.add_module('relu5',nn.ReLU())\n",
        "model.add_module('conv6',nn.Conv2d(128,128,kernel_size=3,padding='same'))\n",
        "model.add_module('relu6',nn.ReLU())\n",
        "model.add_module('pool3',nn.MaxPool2d(2))\n",
        "model.add_module('bn3',nn.BatchNorm2d(128))\n",
        "model.add_module('flatten',nn.Flatten())\n",
        "x= torch.ones((64, 3, 32, 32))\n",
        "#model(x).shape\n",
        "model.add_module('dropout',nn.Dropout(p=0.25))\n",
        "model.add_module('dense',nn.Linear(2048,252))\n",
        "model.add_module('dene2',nn.Linear(252,10))\n",
        "model(x).shape\n",
        "from torchsummary import summary\n",
        "model.cuda()\n",
        "summary(model, (3, 32, 32))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFa_UWm0Yjuj",
        "outputId": "0af2f917-6b10-40f9-dc47-dd74ae824fd2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 32, 32]             896\n",
            "              ReLU-2           [-1, 32, 32, 32]               0\n",
            "            Conv2d-3           [-1, 32, 32, 32]           9,248\n",
            "              ReLU-4           [-1, 32, 32, 32]               0\n",
            "         MaxPool2d-5           [-1, 32, 16, 16]               0\n",
            "       BatchNorm2d-6           [-1, 32, 16, 16]              64\n",
            "            Conv2d-7           [-1, 64, 16, 16]          18,496\n",
            "              ReLU-8           [-1, 64, 16, 16]               0\n",
            "            Conv2d-9           [-1, 64, 16, 16]          36,928\n",
            "             ReLU-10           [-1, 64, 16, 16]               0\n",
            "        MaxPool2d-11             [-1, 64, 8, 8]               0\n",
            "      BatchNorm2d-12             [-1, 64, 8, 8]             128\n",
            "           Conv2d-13            [-1, 128, 8, 8]          73,856\n",
            "             ReLU-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 128, 8, 8]         147,584\n",
            "             ReLU-16            [-1, 128, 8, 8]               0\n",
            "        MaxPool2d-17            [-1, 128, 4, 4]               0\n",
            "      BatchNorm2d-18            [-1, 128, 4, 4]             256\n",
            "          Flatten-19                 [-1, 2048]               0\n",
            "          Dropout-20                 [-1, 2048]               0\n",
            "           Linear-21                  [-1, 252]         516,348\n",
            "           Linear-22                   [-1, 10]           2,530\n",
            "================================================================\n",
            "Total params: 806,334\n",
            "Trainable params: 806,334\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.00\n",
            "Params size (MB): 3.08\n",
            "Estimated Total Size (MB): 5.09\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
      ],
      "metadata": {
        "id": "rFHcWDGFiYBw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "7ddcca02-2a68-449c-aa3e-5430dd1e2fa8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-c0d04b68b6aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Adam' object has no attribute 'cuda'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 3\n",
        "log_interval = 10\n",
        "torch.backends.cudnn.enabled = True\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGHfwgpY56UM",
        "outputId": "cb6e0b1b-6629-4c3c-8474-23dc0fbbb7a1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f6c82f80fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "ktKheBlvsEyf"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for epoch in range(n_epochs+1):\n",
        "  model.train()\n",
        "  correct = 0\n",
        "  for batch_idx, (data, target) in enumerate(train_dl):\n",
        "    data = data.type(torch.cuda.FloatTensor)\n",
        "    #target = target.type(torch.cuda.FloatTensor)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    target = target.squeeze(1)\n",
        "    #output, target = output.type(torch.cuda.FloatTensor), target.type(torch.cuda.FloatTensor)\n",
        "    #loss = F.nll_loss(output, target)\n",
        "    #correct += output.eq(target.data.view_as(output)).sum()\n",
        "    loss = loss_fn(output,target.to(device))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if batch_idx % log_interval == 0:\n",
        "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_idx * len(data), len(train_dl.dataset),100. * batch_idx / len(train_dl), loss.item()))\n",
        "      torch.save(model.state_dict(), 'model.pth')\n",
        "      torch.save(optimizer.state_dict(), 'optimizer.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxoDD2Y05Y4D",
        "outputId": "d4638955-7164-425b-be69-f0ac36f9e70c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 0 [0/50000 (0%)]\tLoss: 2.402951\n",
            "Train Epoch: 0 [640/50000 (1%)]\tLoss: 2.425147\n",
            "Train Epoch: 0 [1280/50000 (3%)]\tLoss: 2.431018\n",
            "Train Epoch: 0 [1920/50000 (4%)]\tLoss: 2.268883\n",
            "Train Epoch: 0 [2560/50000 (5%)]\tLoss: 2.148796\n",
            "Train Epoch: 0 [3200/50000 (6%)]\tLoss: 1.995610\n",
            "Train Epoch: 0 [3840/50000 (8%)]\tLoss: 1.993605\n",
            "Train Epoch: 0 [4480/50000 (9%)]\tLoss: 2.082136\n",
            "Train Epoch: 0 [5120/50000 (10%)]\tLoss: 2.276104\n",
            "Train Epoch: 0 [5760/50000 (12%)]\tLoss: 1.946165\n",
            "Train Epoch: 0 [6400/50000 (13%)]\tLoss: 1.577542\n",
            "Train Epoch: 0 [7040/50000 (14%)]\tLoss: 2.157639\n",
            "Train Epoch: 0 [7680/50000 (15%)]\tLoss: 1.932746\n",
            "Train Epoch: 0 [8320/50000 (17%)]\tLoss: 1.957900\n",
            "Train Epoch: 0 [8960/50000 (18%)]\tLoss: 1.997017\n",
            "Train Epoch: 0 [9600/50000 (19%)]\tLoss: 1.884007\n",
            "Train Epoch: 0 [10240/50000 (20%)]\tLoss: 1.816674\n",
            "Train Epoch: 0 [10880/50000 (22%)]\tLoss: 1.806380\n",
            "Train Epoch: 0 [11520/50000 (23%)]\tLoss: 1.558045\n",
            "Train Epoch: 0 [12160/50000 (24%)]\tLoss: 2.073604\n",
            "Train Epoch: 0 [12800/50000 (26%)]\tLoss: 1.775179\n",
            "Train Epoch: 0 [13440/50000 (27%)]\tLoss: 2.100417\n",
            "Train Epoch: 0 [14080/50000 (28%)]\tLoss: 1.776707\n",
            "Train Epoch: 0 [14720/50000 (29%)]\tLoss: 1.708975\n",
            "Train Epoch: 0 [15360/50000 (31%)]\tLoss: 1.845154\n",
            "Train Epoch: 0 [16000/50000 (32%)]\tLoss: 1.612731\n",
            "Train Epoch: 0 [16640/50000 (33%)]\tLoss: 1.781999\n",
            "Train Epoch: 0 [17280/50000 (35%)]\tLoss: 1.692601\n",
            "Train Epoch: 0 [17920/50000 (36%)]\tLoss: 1.727734\n",
            "Train Epoch: 0 [18560/50000 (37%)]\tLoss: 1.666057\n",
            "Train Epoch: 0 [19200/50000 (38%)]\tLoss: 1.801915\n",
            "Train Epoch: 0 [19840/50000 (40%)]\tLoss: 1.702221\n",
            "Train Epoch: 0 [20480/50000 (41%)]\tLoss: 1.634011\n",
            "Train Epoch: 0 [21120/50000 (42%)]\tLoss: 1.744432\n",
            "Train Epoch: 0 [21760/50000 (43%)]\tLoss: 1.624565\n",
            "Train Epoch: 0 [22400/50000 (45%)]\tLoss: 1.700801\n",
            "Train Epoch: 0 [23040/50000 (46%)]\tLoss: 1.645752\n",
            "Train Epoch: 0 [23680/50000 (47%)]\tLoss: 1.696644\n",
            "Train Epoch: 0 [24320/50000 (49%)]\tLoss: 1.849224\n",
            "Train Epoch: 0 [24960/50000 (50%)]\tLoss: 1.670170\n",
            "Train Epoch: 0 [25600/50000 (51%)]\tLoss: 1.884281\n",
            "Train Epoch: 0 [26240/50000 (52%)]\tLoss: 1.773206\n",
            "Train Epoch: 0 [26880/50000 (54%)]\tLoss: 1.668409\n",
            "Train Epoch: 0 [27520/50000 (55%)]\tLoss: 1.690897\n",
            "Train Epoch: 0 [28160/50000 (56%)]\tLoss: 1.802198\n",
            "Train Epoch: 0 [28800/50000 (58%)]\tLoss: 1.770055\n",
            "Train Epoch: 0 [29440/50000 (59%)]\tLoss: 1.806134\n",
            "Train Epoch: 0 [30080/50000 (60%)]\tLoss: 1.598889\n",
            "Train Epoch: 0 [30720/50000 (61%)]\tLoss: 1.734899\n",
            "Train Epoch: 0 [31360/50000 (63%)]\tLoss: 1.494548\n",
            "Train Epoch: 0 [32000/50000 (64%)]\tLoss: 1.651777\n",
            "Train Epoch: 0 [32640/50000 (65%)]\tLoss: 1.812757\n",
            "Train Epoch: 0 [33280/50000 (66%)]\tLoss: 1.355374\n",
            "Train Epoch: 0 [33920/50000 (68%)]\tLoss: 1.432329\n",
            "Train Epoch: 0 [34560/50000 (69%)]\tLoss: 1.521877\n",
            "Train Epoch: 0 [35200/50000 (70%)]\tLoss: 1.576864\n",
            "Train Epoch: 0 [35840/50000 (72%)]\tLoss: 1.695375\n",
            "Train Epoch: 0 [36480/50000 (73%)]\tLoss: 1.647532\n",
            "Train Epoch: 0 [37120/50000 (74%)]\tLoss: 1.663631\n",
            "Train Epoch: 0 [37760/50000 (75%)]\tLoss: 1.903736\n",
            "Train Epoch: 0 [38400/50000 (77%)]\tLoss: 1.313883\n",
            "Train Epoch: 0 [39040/50000 (78%)]\tLoss: 1.585355\n",
            "Train Epoch: 0 [39680/50000 (79%)]\tLoss: 1.567089\n",
            "Train Epoch: 0 [40320/50000 (81%)]\tLoss: 1.504876\n",
            "Train Epoch: 0 [40960/50000 (82%)]\tLoss: 1.574824\n",
            "Train Epoch: 0 [41600/50000 (83%)]\tLoss: 1.483606\n",
            "Train Epoch: 0 [42240/50000 (84%)]\tLoss: 1.594177\n",
            "Train Epoch: 0 [42880/50000 (86%)]\tLoss: 1.412392\n",
            "Train Epoch: 0 [43520/50000 (87%)]\tLoss: 1.597983\n",
            "Train Epoch: 0 [44160/50000 (88%)]\tLoss: 1.713204\n",
            "Train Epoch: 0 [44800/50000 (90%)]\tLoss: 1.971283\n",
            "Train Epoch: 0 [45440/50000 (91%)]\tLoss: 1.600322\n",
            "Train Epoch: 0 [46080/50000 (92%)]\tLoss: 1.663187\n",
            "Train Epoch: 0 [46720/50000 (93%)]\tLoss: 1.473102\n",
            "Train Epoch: 0 [47360/50000 (95%)]\tLoss: 1.924439\n",
            "Train Epoch: 0 [48000/50000 (96%)]\tLoss: 1.464482\n",
            "Train Epoch: 0 [48640/50000 (97%)]\tLoss: 1.793759\n",
            "Train Epoch: 0 [49280/50000 (98%)]\tLoss: 1.826308\n",
            "Train Epoch: 0 [49920/50000 (100%)]\tLoss: 1.749204\n",
            "Train Epoch: 1 [0/50000 (0%)]\tLoss: 1.742909\n",
            "Train Epoch: 1 [640/50000 (1%)]\tLoss: 1.435066\n",
            "Train Epoch: 1 [1280/50000 (3%)]\tLoss: 1.436208\n",
            "Train Epoch: 1 [1920/50000 (4%)]\tLoss: 1.584686\n",
            "Train Epoch: 1 [2560/50000 (5%)]\tLoss: 1.562590\n",
            "Train Epoch: 1 [3200/50000 (6%)]\tLoss: 1.570120\n",
            "Train Epoch: 1 [3840/50000 (8%)]\tLoss: 1.515013\n",
            "Train Epoch: 1 [4480/50000 (9%)]\tLoss: 1.412550\n",
            "Train Epoch: 1 [5120/50000 (10%)]\tLoss: 1.673780\n",
            "Train Epoch: 1 [5760/50000 (12%)]\tLoss: 1.498036\n",
            "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 1.743381\n",
            "Train Epoch: 1 [7040/50000 (14%)]\tLoss: 1.388071\n",
            "Train Epoch: 1 [7680/50000 (15%)]\tLoss: 1.658815\n",
            "Train Epoch: 1 [8320/50000 (17%)]\tLoss: 1.749771\n",
            "Train Epoch: 1 [8960/50000 (18%)]\tLoss: 1.347604\n",
            "Train Epoch: 1 [9600/50000 (19%)]\tLoss: 1.441324\n",
            "Train Epoch: 1 [10240/50000 (20%)]\tLoss: 1.750630\n",
            "Train Epoch: 1 [10880/50000 (22%)]\tLoss: 1.358916\n",
            "Train Epoch: 1 [11520/50000 (23%)]\tLoss: 1.510233\n",
            "Train Epoch: 1 [12160/50000 (24%)]\tLoss: 1.484595\n",
            "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 1.572418\n",
            "Train Epoch: 1 [13440/50000 (27%)]\tLoss: 1.921014\n",
            "Train Epoch: 1 [14080/50000 (28%)]\tLoss: 1.592998\n",
            "Train Epoch: 1 [14720/50000 (29%)]\tLoss: 1.465556\n",
            "Train Epoch: 1 [15360/50000 (31%)]\tLoss: 1.584450\n",
            "Train Epoch: 1 [16000/50000 (32%)]\tLoss: 1.521692\n",
            "Train Epoch: 1 [16640/50000 (33%)]\tLoss: 1.669190\n",
            "Train Epoch: 1 [17280/50000 (35%)]\tLoss: 1.416350\n",
            "Train Epoch: 1 [17920/50000 (36%)]\tLoss: 1.726722\n",
            "Train Epoch: 1 [18560/50000 (37%)]\tLoss: 1.508840\n",
            "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 1.735832\n",
            "Train Epoch: 1 [19840/50000 (40%)]\tLoss: 1.647562\n",
            "Train Epoch: 1 [20480/50000 (41%)]\tLoss: 1.523553\n",
            "Train Epoch: 1 [21120/50000 (42%)]\tLoss: 1.368755\n",
            "Train Epoch: 1 [21760/50000 (43%)]\tLoss: 1.519492\n",
            "Train Epoch: 1 [22400/50000 (45%)]\tLoss: 1.287945\n",
            "Train Epoch: 1 [23040/50000 (46%)]\tLoss: 1.548558\n",
            "Train Epoch: 1 [23680/50000 (47%)]\tLoss: 1.618173\n",
            "Train Epoch: 1 [24320/50000 (49%)]\tLoss: 1.684602\n",
            "Train Epoch: 1 [24960/50000 (50%)]\tLoss: 1.536680\n",
            "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.429784\n",
            "Train Epoch: 1 [26240/50000 (52%)]\tLoss: 1.395235\n",
            "Train Epoch: 1 [26880/50000 (54%)]\tLoss: 1.446199\n",
            "Train Epoch: 1 [27520/50000 (55%)]\tLoss: 1.678711\n",
            "Train Epoch: 1 [28160/50000 (56%)]\tLoss: 1.390173\n",
            "Train Epoch: 1 [28800/50000 (58%)]\tLoss: 1.367891\n",
            "Train Epoch: 1 [29440/50000 (59%)]\tLoss: 1.493405\n",
            "Train Epoch: 1 [30080/50000 (60%)]\tLoss: 1.404168\n",
            "Train Epoch: 1 [30720/50000 (61%)]\tLoss: 1.302168\n",
            "Train Epoch: 1 [31360/50000 (63%)]\tLoss: 1.630680\n",
            "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 1.526091\n",
            "Train Epoch: 1 [32640/50000 (65%)]\tLoss: 1.410016\n",
            "Train Epoch: 1 [33280/50000 (66%)]\tLoss: 1.548526\n",
            "Train Epoch: 1 [33920/50000 (68%)]\tLoss: 1.510084\n",
            "Train Epoch: 1 [34560/50000 (69%)]\tLoss: 1.216311\n",
            "Train Epoch: 1 [35200/50000 (70%)]\tLoss: 1.429003\n",
            "Train Epoch: 1 [35840/50000 (72%)]\tLoss: 1.453739\n",
            "Train Epoch: 1 [36480/50000 (73%)]\tLoss: 1.533490\n",
            "Train Epoch: 1 [37120/50000 (74%)]\tLoss: 1.379103\n",
            "Train Epoch: 1 [37760/50000 (75%)]\tLoss: 1.462454\n",
            "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.545313\n",
            "Train Epoch: 1 [39040/50000 (78%)]\tLoss: 1.501602\n",
            "Train Epoch: 1 [39680/50000 (79%)]\tLoss: 1.511093\n",
            "Train Epoch: 1 [40320/50000 (81%)]\tLoss: 1.193991\n",
            "Train Epoch: 1 [40960/50000 (82%)]\tLoss: 1.396490\n",
            "Train Epoch: 1 [41600/50000 (83%)]\tLoss: 1.115117\n",
            "Train Epoch: 1 [42240/50000 (84%)]\tLoss: 1.489361\n",
            "Train Epoch: 1 [42880/50000 (86%)]\tLoss: 1.417109\n",
            "Train Epoch: 1 [43520/50000 (87%)]\tLoss: 1.025954\n",
            "Train Epoch: 1 [44160/50000 (88%)]\tLoss: 1.402374\n",
            "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 1.399367\n",
            "Train Epoch: 1 [45440/50000 (91%)]\tLoss: 1.556391\n",
            "Train Epoch: 1 [46080/50000 (92%)]\tLoss: 1.421196\n",
            "Train Epoch: 1 [46720/50000 (93%)]\tLoss: 1.421300\n",
            "Train Epoch: 1 [47360/50000 (95%)]\tLoss: 1.456482\n",
            "Train Epoch: 1 [48000/50000 (96%)]\tLoss: 1.332198\n",
            "Train Epoch: 1 [48640/50000 (97%)]\tLoss: 1.321170\n",
            "Train Epoch: 1 [49280/50000 (98%)]\tLoss: 1.561120\n",
            "Train Epoch: 1 [49920/50000 (100%)]\tLoss: 1.435591\n",
            "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.612336\n",
            "Train Epoch: 2 [640/50000 (1%)]\tLoss: 1.528523\n",
            "Train Epoch: 2 [1280/50000 (3%)]\tLoss: 1.311309\n",
            "Train Epoch: 2 [1920/50000 (4%)]\tLoss: 1.177380\n",
            "Train Epoch: 2 [2560/50000 (5%)]\tLoss: 1.716401\n",
            "Train Epoch: 2 [3200/50000 (6%)]\tLoss: 1.587854\n",
            "Train Epoch: 2 [3840/50000 (8%)]\tLoss: 1.377770\n",
            "Train Epoch: 2 [4480/50000 (9%)]\tLoss: 1.384151\n",
            "Train Epoch: 2 [5120/50000 (10%)]\tLoss: 1.357109\n",
            "Train Epoch: 2 [5760/50000 (12%)]\tLoss: 1.329221\n",
            "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 1.587929\n",
            "Train Epoch: 2 [7040/50000 (14%)]\tLoss: 1.389440\n",
            "Train Epoch: 2 [7680/50000 (15%)]\tLoss: 1.556653\n",
            "Train Epoch: 2 [8320/50000 (17%)]\tLoss: 1.495684\n",
            "Train Epoch: 2 [8960/50000 (18%)]\tLoss: 1.432720\n",
            "Train Epoch: 2 [9600/50000 (19%)]\tLoss: 1.209098\n",
            "Train Epoch: 2 [10240/50000 (20%)]\tLoss: 1.518763\n",
            "Train Epoch: 2 [10880/50000 (22%)]\tLoss: 1.366005\n",
            "Train Epoch: 2 [11520/50000 (23%)]\tLoss: 1.576401\n",
            "Train Epoch: 2 [12160/50000 (24%)]\tLoss: 1.448023\n",
            "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.360572\n",
            "Train Epoch: 2 [13440/50000 (27%)]\tLoss: 1.286518\n",
            "Train Epoch: 2 [14080/50000 (28%)]\tLoss: 1.300141\n",
            "Train Epoch: 2 [14720/50000 (29%)]\tLoss: 1.288444\n",
            "Train Epoch: 2 [15360/50000 (31%)]\tLoss: 1.496230\n",
            "Train Epoch: 2 [16000/50000 (32%)]\tLoss: 1.266769\n",
            "Train Epoch: 2 [16640/50000 (33%)]\tLoss: 1.404948\n",
            "Train Epoch: 2 [17280/50000 (35%)]\tLoss: 1.480595\n",
            "Train Epoch: 2 [17920/50000 (36%)]\tLoss: 1.477952\n",
            "Train Epoch: 2 [18560/50000 (37%)]\tLoss: 1.560014\n",
            "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 1.282920\n",
            "Train Epoch: 2 [19840/50000 (40%)]\tLoss: 1.457498\n",
            "Train Epoch: 2 [20480/50000 (41%)]\tLoss: 1.311777\n",
            "Train Epoch: 2 [21120/50000 (42%)]\tLoss: 1.339103\n",
            "Train Epoch: 2 [21760/50000 (43%)]\tLoss: 1.463733\n",
            "Train Epoch: 2 [22400/50000 (45%)]\tLoss: 1.396647\n",
            "Train Epoch: 2 [23040/50000 (46%)]\tLoss: 1.492783\n",
            "Train Epoch: 2 [23680/50000 (47%)]\tLoss: 1.395281\n",
            "Train Epoch: 2 [24320/50000 (49%)]\tLoss: 1.122672\n",
            "Train Epoch: 2 [24960/50000 (50%)]\tLoss: 1.367325\n",
            "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.504534\n",
            "Train Epoch: 2 [26240/50000 (52%)]\tLoss: 1.352506\n",
            "Train Epoch: 2 [26880/50000 (54%)]\tLoss: 1.245998\n",
            "Train Epoch: 2 [27520/50000 (55%)]\tLoss: 1.381428\n",
            "Train Epoch: 2 [28160/50000 (56%)]\tLoss: 1.628325\n",
            "Train Epoch: 2 [28800/50000 (58%)]\tLoss: 1.422861\n",
            "Train Epoch: 2 [29440/50000 (59%)]\tLoss: 1.409510\n",
            "Train Epoch: 2 [30080/50000 (60%)]\tLoss: 1.380399\n",
            "Train Epoch: 2 [30720/50000 (61%)]\tLoss: 1.313882\n",
            "Train Epoch: 2 [31360/50000 (63%)]\tLoss: 1.208815\n",
            "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 1.571326\n",
            "Train Epoch: 2 [32640/50000 (65%)]\tLoss: 1.120053\n",
            "Train Epoch: 2 [33280/50000 (66%)]\tLoss: 1.243668\n",
            "Train Epoch: 2 [33920/50000 (68%)]\tLoss: 1.191087\n",
            "Train Epoch: 2 [34560/50000 (69%)]\tLoss: 1.448111\n",
            "Train Epoch: 2 [35200/50000 (70%)]\tLoss: 1.348432\n",
            "Train Epoch: 2 [35840/50000 (72%)]\tLoss: 1.146271\n",
            "Train Epoch: 2 [36480/50000 (73%)]\tLoss: 1.567505\n",
            "Train Epoch: 2 [37120/50000 (74%)]\tLoss: 1.315324\n",
            "Train Epoch: 2 [37760/50000 (75%)]\tLoss: 1.061605\n",
            "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.501923\n",
            "Train Epoch: 2 [39040/50000 (78%)]\tLoss: 1.167164\n",
            "Train Epoch: 2 [39680/50000 (79%)]\tLoss: 1.212316\n",
            "Train Epoch: 2 [40320/50000 (81%)]\tLoss: 1.290635\n",
            "Train Epoch: 2 [40960/50000 (82%)]\tLoss: 1.095576\n",
            "Train Epoch: 2 [41600/50000 (83%)]\tLoss: 1.288642\n",
            "Train Epoch: 2 [42240/50000 (84%)]\tLoss: 1.426206\n",
            "Train Epoch: 2 [42880/50000 (86%)]\tLoss: 1.554612\n",
            "Train Epoch: 2 [43520/50000 (87%)]\tLoss: 1.323552\n",
            "Train Epoch: 2 [44160/50000 (88%)]\tLoss: 1.383211\n",
            "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 1.340031\n",
            "Train Epoch: 2 [45440/50000 (91%)]\tLoss: 1.383964\n",
            "Train Epoch: 2 [46080/50000 (92%)]\tLoss: 1.377393\n",
            "Train Epoch: 2 [46720/50000 (93%)]\tLoss: 1.269900\n",
            "Train Epoch: 2 [47360/50000 (95%)]\tLoss: 1.250478\n",
            "Train Epoch: 2 [48000/50000 (96%)]\tLoss: 1.134560\n",
            "Train Epoch: 2 [48640/50000 (97%)]\tLoss: 1.479795\n",
            "Train Epoch: 2 [49280/50000 (98%)]\tLoss: 1.426851\n",
            "Train Epoch: 2 [49920/50000 (100%)]\tLoss: 1.340420\n",
            "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.751865\n",
            "Train Epoch: 3 [640/50000 (1%)]\tLoss: 1.348116\n",
            "Train Epoch: 3 [1280/50000 (3%)]\tLoss: 1.456849\n",
            "Train Epoch: 3 [1920/50000 (4%)]\tLoss: 1.304161\n",
            "Train Epoch: 3 [2560/50000 (5%)]\tLoss: 1.070339\n",
            "Train Epoch: 3 [3200/50000 (6%)]\tLoss: 1.331922\n",
            "Train Epoch: 3 [3840/50000 (8%)]\tLoss: 1.493330\n",
            "Train Epoch: 3 [4480/50000 (9%)]\tLoss: 1.453887\n",
            "Train Epoch: 3 [5120/50000 (10%)]\tLoss: 1.204621\n",
            "Train Epoch: 3 [5760/50000 (12%)]\tLoss: 1.520912\n",
            "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 1.341484\n",
            "Train Epoch: 3 [7040/50000 (14%)]\tLoss: 1.257432\n",
            "Train Epoch: 3 [7680/50000 (15%)]\tLoss: 1.480860\n",
            "Train Epoch: 3 [8320/50000 (17%)]\tLoss: 1.172687\n",
            "Train Epoch: 3 [8960/50000 (18%)]\tLoss: 1.300067\n",
            "Train Epoch: 3 [9600/50000 (19%)]\tLoss: 1.210362\n",
            "Train Epoch: 3 [10240/50000 (20%)]\tLoss: 1.371760\n",
            "Train Epoch: 3 [10880/50000 (22%)]\tLoss: 1.540410\n",
            "Train Epoch: 3 [11520/50000 (23%)]\tLoss: 1.237951\n",
            "Train Epoch: 3 [12160/50000 (24%)]\tLoss: 1.175499\n",
            "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 1.203844\n",
            "Train Epoch: 3 [13440/50000 (27%)]\tLoss: 1.365978\n",
            "Train Epoch: 3 [14080/50000 (28%)]\tLoss: 1.223731\n",
            "Train Epoch: 3 [14720/50000 (29%)]\tLoss: 1.106991\n",
            "Train Epoch: 3 [15360/50000 (31%)]\tLoss: 1.305484\n",
            "Train Epoch: 3 [16000/50000 (32%)]\tLoss: 1.057101\n",
            "Train Epoch: 3 [16640/50000 (33%)]\tLoss: 1.234033\n",
            "Train Epoch: 3 [17280/50000 (35%)]\tLoss: 1.338555\n",
            "Train Epoch: 3 [17920/50000 (36%)]\tLoss: 1.363133\n",
            "Train Epoch: 3 [18560/50000 (37%)]\tLoss: 1.274517\n",
            "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 1.450866\n",
            "Train Epoch: 3 [19840/50000 (40%)]\tLoss: 1.265458\n",
            "Train Epoch: 3 [20480/50000 (41%)]\tLoss: 1.245825\n",
            "Train Epoch: 3 [21120/50000 (42%)]\tLoss: 1.085196\n",
            "Train Epoch: 3 [21760/50000 (43%)]\tLoss: 1.313327\n",
            "Train Epoch: 3 [22400/50000 (45%)]\tLoss: 1.342094\n",
            "Train Epoch: 3 [23040/50000 (46%)]\tLoss: 1.237936\n",
            "Train Epoch: 3 [23680/50000 (47%)]\tLoss: 1.159930\n",
            "Train Epoch: 3 [24320/50000 (49%)]\tLoss: 1.211018\n",
            "Train Epoch: 3 [24960/50000 (50%)]\tLoss: 1.329797\n",
            "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 0.980642\n",
            "Train Epoch: 3 [26240/50000 (52%)]\tLoss: 1.245821\n",
            "Train Epoch: 3 [26880/50000 (54%)]\tLoss: 1.366509\n",
            "Train Epoch: 3 [27520/50000 (55%)]\tLoss: 1.072034\n",
            "Train Epoch: 3 [28160/50000 (56%)]\tLoss: 1.277218\n",
            "Train Epoch: 3 [28800/50000 (58%)]\tLoss: 1.219637\n",
            "Train Epoch: 3 [29440/50000 (59%)]\tLoss: 1.257880\n",
            "Train Epoch: 3 [30080/50000 (60%)]\tLoss: 1.261662\n",
            "Train Epoch: 3 [30720/50000 (61%)]\tLoss: 1.180333\n",
            "Train Epoch: 3 [31360/50000 (63%)]\tLoss: 1.140155\n",
            "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 1.198750\n",
            "Train Epoch: 3 [32640/50000 (65%)]\tLoss: 1.101819\n",
            "Train Epoch: 3 [33280/50000 (66%)]\tLoss: 1.310376\n",
            "Train Epoch: 3 [33920/50000 (68%)]\tLoss: 1.129694\n",
            "Train Epoch: 3 [34560/50000 (69%)]\tLoss: 1.144311\n",
            "Train Epoch: 3 [35200/50000 (70%)]\tLoss: 1.194881\n",
            "Train Epoch: 3 [35840/50000 (72%)]\tLoss: 1.071227\n",
            "Train Epoch: 3 [36480/50000 (73%)]\tLoss: 1.495511\n",
            "Train Epoch: 3 [37120/50000 (74%)]\tLoss: 1.350140\n",
            "Train Epoch: 3 [37760/50000 (75%)]\tLoss: 1.287764\n",
            "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 1.195022\n",
            "Train Epoch: 3 [39040/50000 (78%)]\tLoss: 1.213894\n",
            "Train Epoch: 3 [39680/50000 (79%)]\tLoss: 1.207179\n",
            "Train Epoch: 3 [40320/50000 (81%)]\tLoss: 1.165570\n",
            "Train Epoch: 3 [40960/50000 (82%)]\tLoss: 1.292397\n",
            "Train Epoch: 3 [41600/50000 (83%)]\tLoss: 1.126093\n",
            "Train Epoch: 3 [42240/50000 (84%)]\tLoss: 1.125243\n",
            "Train Epoch: 3 [42880/50000 (86%)]\tLoss: 1.309163\n",
            "Train Epoch: 3 [43520/50000 (87%)]\tLoss: 1.207007\n",
            "Train Epoch: 3 [44160/50000 (88%)]\tLoss: 1.324727\n",
            "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 1.169186\n",
            "Train Epoch: 3 [45440/50000 (91%)]\tLoss: 1.231612\n",
            "Train Epoch: 3 [46080/50000 (92%)]\tLoss: 1.153218\n",
            "Train Epoch: 3 [46720/50000 (93%)]\tLoss: 1.421113\n",
            "Train Epoch: 3 [47360/50000 (95%)]\tLoss: 1.103712\n",
            "Train Epoch: 3 [48000/50000 (96%)]\tLoss: 1.280716\n",
            "Train Epoch: 3 [48640/50000 (97%)]\tLoss: 1.649182\n",
            "Train Epoch: 3 [49280/50000 (98%)]\tLoss: 1.377069\n",
            "Train Epoch: 3 [49920/50000 (100%)]\tLoss: 1.041842\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model #= Net()\n",
        "#Model=model\n",
        "model.load_state_dict(torch.load('model.pth'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUjrJZpJ6jAV",
        "outputId": "ac07cfd6-131d-47c8-8a26-5ac1c3195fdd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "test = x_test[50].reshape(1,3,32,32)\n",
        "print(y_test[50])\n",
        "test.shape\n",
        "test = test.type(torch.cuda.FloatTensor)\n",
        "print(torch.argmax(model(test),dim=1))#.dtype)\n",
        "plt.imshow(test.to(torch.uint8).cpu().numpy().reshape(32,32,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "YAHahUTtGGPP",
        "outputId": "48c3a636-291d-4bb6-eadc-5bd2936dcf28"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([9], dtype=torch.uint8)\n",
            "tensor([9], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6c70bdeb50>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.imshow(test.to(torch.uint8).numpy().reshape(32,32,3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "D8uXuaB6J3SU",
        "outputId": "3b91fd3e-6606-49f1-9dc7-8d764daefdc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f03e204dad0>"
            ]
          },
          "metadata": {},
          "execution_count": 155
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Fb6Ho9oL-0j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
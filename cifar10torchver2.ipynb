{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPoGgGfMLXFbmI7MeZiBzka",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ngcthanh2903/pytorch/blob/main/cifar10torchver2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qypfIwICYrKF"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import cifar10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) =cifar10.load_data()\n",
        "print(x_test.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LAEjM7gZS9R",
        "outputId": "965c312a-aa00-4587-c114-f9907c3be1d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "uint8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=x_train.reshape(-1,3,32,32)\n",
        "x_test=x_test.reshape(-1,3,32,32)\n"
      ],
      "metadata": {
        "id": "_OGWSIOvZsuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seL4uDNpaZup",
        "outputId": "7d21cf14-1499-4b81-e290-5a13bdbf83d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 3, 32, 32)\n",
            "(10000, 3, 32, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim.adam as adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import TensorDataset\n",
        "from torchsummary import summary\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "Vt8mn0h3alQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.from_numpy(x_train)\n",
        "y_train = torch.from_numpy(y_train)\n",
        "x_test = torch.from_numpy(x_test)\n",
        "y_test = torch.from_numpy(y_test)\n",
        "x_train = x_train.to(torch.float32)\n",
        "x_test = x_test.to(torch.float32)"
      ],
      "metadata": {
        "id": "PkqEs0XscgVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size =64\n",
        "train_ds = TensorDataset(x_train,y_train)\n",
        "test_ds = TensorDataset(x_test,y_test)\n",
        "train_dl = DataLoader(train_ds,batch_size,shuffle=True)\n",
        "test_dl = DataLoader(test_ds,batch_size,shuffle=True)"
      ],
      "metadata": {
        "id": "Im4d1ajZh5Vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yR1BctsI6aUL",
        "outputId": "418058b8-0973-439e-90bf-489a620913d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3,padding=2)\n",
        "        self.conv2 = nn.Conv2d(32,64,kernel_size= 3,padding=2)\n",
        "        self.conv3 = nn.Conv2d(64,64,kernel_size=3,padding=2)\n",
        "        self.conv3_drop = nn.Dropout2d()\n",
        "        self.conv4 = nn.Conv2d(64,128,kernel_size=3,padding=2)\n",
        "        self.fc1 = nn.Linear(1152, 100)\n",
        "        self.fc2 = nn.Linear(100, 10)\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv3_drop(self.conv3(x)), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv4(x), 2))\n",
        "        #print(x.shape)\n",
        "        #print(x.reshape(x.shape[0],-1).shape)\n",
        "        x = x.view(-1, 1152)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x)"
      ],
      "metadata": {
        "id": "o59tizgciA_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "model = Net()\n",
        "summary(model, (3, 32, 32))\n",
        "loss_fn = CrossEntropyLoss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8GSanp5iLgS",
        "outputId": "79c30f35-7f70-4bf4-e501-f904c02bb05f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 34, 34]             896\n",
            "            Conv2d-2           [-1, 64, 19, 19]          18,496\n",
            "            Conv2d-3           [-1, 64, 11, 11]          36,928\n",
            "         Dropout2d-4           [-1, 64, 11, 11]               0\n",
            "            Conv2d-5            [-1, 128, 7, 7]          73,856\n",
            "            Linear-6                  [-1, 100]         115,300\n",
            "            Linear-7                   [-1, 10]           1,010\n",
            "================================================================\n",
            "Total params: 246,486\n",
            "Trainable params: 246,486\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.63\n",
            "Params size (MB): 0.94\n",
            "Estimated Total Size (MB): 1.58\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential()\n",
        "model.add_module('conv1',nn.Conv2d(3,32,kernel_size=3,padding = 'same'))\n",
        "model.add_module('relu1',nn.ReLU())\n",
        "model.add_module('conv2',nn.Conv2d(32,32,kernel_size=3,padding='same'))\n",
        "model.add_module('relu2',nn.ReLU())\n",
        "model.add_module('pool1',nn.MaxPool2d(2))\n",
        "model.add_module('bn1',nn.BatchNorm2d(32))\n",
        "\n",
        "model.add_module('conv3',nn.Conv2d(32,64,kernel_size=3,padding = 'same'))\n",
        "model.add_module('relu3',nn.ReLU())\n",
        "model.add_module('conv4',nn.Conv2d(64,64,kernel_size=3,padding='same'))\n",
        "model.add_module('relu4',nn.ReLU())\n",
        "model.add_module('pool2',nn.MaxPool2d(2))\n",
        "model.add_module('bn2',nn.BatchNorm2d(64))\n",
        "\n",
        "model.add_module('conv5',nn.Conv2d(64,128,kernel_size=3,padding = 'same'))\n",
        "model.add_module('relu5',nn.ReLU())\n",
        "model.add_module('conv6',nn.Conv2d(128,128,kernel_size=3,padding='same'))\n",
        "model.add_module('relu6',nn.ReLU())\n",
        "model.add_module('pool3',nn.MaxPool2d(2))\n",
        "model.add_module('bn3',nn.BatchNorm2d(128))\n",
        "model.add_module('flatten',nn.Flatten())\n",
        "x= torch.ones((64, 3, 32, 32))\n",
        "#model(x).shape\n",
        "model.add_module('dropout',nn.Dropout(p=0.25))\n",
        "model.add_module('dense',nn.Linear(2048,252))\n",
        "model.add_module('dene2',nn.Linear(252,10))\n",
        "model(x).shape\n",
        "from torchsummary import summary\n",
        "summary(model, (3, 32, 32))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFa_UWm0Yjuj",
        "outputId": "152fb200-09f2-4845-e766-dde523dd4414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 32, 32]             896\n",
            "              ReLU-2           [-1, 32, 32, 32]               0\n",
            "            Conv2d-3           [-1, 32, 32, 32]           9,248\n",
            "              ReLU-4           [-1, 32, 32, 32]               0\n",
            "         MaxPool2d-5           [-1, 32, 16, 16]               0\n",
            "       BatchNorm2d-6           [-1, 32, 16, 16]              64\n",
            "            Conv2d-7           [-1, 64, 16, 16]          18,496\n",
            "              ReLU-8           [-1, 64, 16, 16]               0\n",
            "            Conv2d-9           [-1, 64, 16, 16]          36,928\n",
            "             ReLU-10           [-1, 64, 16, 16]               0\n",
            "        MaxPool2d-11             [-1, 64, 8, 8]               0\n",
            "      BatchNorm2d-12             [-1, 64, 8, 8]             128\n",
            "           Conv2d-13            [-1, 128, 8, 8]          73,856\n",
            "             ReLU-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 128, 8, 8]         147,584\n",
            "             ReLU-16            [-1, 128, 8, 8]               0\n",
            "        MaxPool2d-17            [-1, 128, 4, 4]               0\n",
            "      BatchNorm2d-18            [-1, 128, 4, 4]             256\n",
            "          Flatten-19                 [-1, 2048]               0\n",
            "          Dropout-20                 [-1, 2048]               0\n",
            "           Linear-21                  [-1, 252]         516,348\n",
            "           Linear-22                   [-1, 10]           2,530\n",
            "================================================================\n",
            "Total params: 806,334\n",
            "Trainable params: 806,334\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.00\n",
            "Params size (MB): 3.08\n",
            "Estimated Total Size (MB): 5.09\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "rFHcWDGFiYBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 3\n",
        "log_interval = 10\n",
        "torch.backends.cudnn.enabled = False\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGHfwgpY56UM",
        "outputId": "4f305f2b-b1b0-49dd-cba2-e09ee4a6ff8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f03e90d5f30>"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(n_epochs+1):\n",
        "  model.train()\n",
        "  correct = 0\n",
        "  for batch_idx, (data, target) in enumerate(train_dl):\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    target = target.squeeze(1)\n",
        "    #loss = F.nll_loss(output, target)\n",
        "    #correct += output.eq(target.data.view_as(output)).sum()\n",
        "    loss = loss_fn(output,target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if batch_idx % log_interval == 0:\n",
        "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_idx * len(data), len(train_dl.dataset),100. * batch_idx / len(train_dl), loss.item()))\n",
        "      torch.save(model.state_dict(), 'model.pth')\n",
        "      torch.save(optimizer.state_dict(), 'optimizer.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxoDD2Y05Y4D",
        "outputId": "df747ab1-f587-4745-cb4d-513269c0a130"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 0 [0/50000 (0%)]\tLoss: 2.364173\n",
            "Train Epoch: 0 [640/50000 (1%)]\tLoss: 2.302790\n",
            "Train Epoch: 0 [1280/50000 (3%)]\tLoss: 2.381250\n",
            "Train Epoch: 0 [1920/50000 (4%)]\tLoss: 2.046334\n",
            "Train Epoch: 0 [2560/50000 (5%)]\tLoss: 2.320073\n",
            "Train Epoch: 0 [3200/50000 (6%)]\tLoss: 2.341022\n",
            "Train Epoch: 0 [3840/50000 (8%)]\tLoss: 2.389270\n",
            "Train Epoch: 0 [4480/50000 (9%)]\tLoss: 2.084774\n",
            "Train Epoch: 0 [5120/50000 (10%)]\tLoss: 1.990979\n",
            "Train Epoch: 0 [5760/50000 (12%)]\tLoss: 2.121101\n",
            "Train Epoch: 0 [6400/50000 (13%)]\tLoss: 1.909057\n",
            "Train Epoch: 0 [7040/50000 (14%)]\tLoss: 2.007921\n",
            "Train Epoch: 0 [7680/50000 (15%)]\tLoss: 2.063899\n",
            "Train Epoch: 0 [8320/50000 (17%)]\tLoss: 1.929135\n",
            "Train Epoch: 0 [8960/50000 (18%)]\tLoss: 2.056941\n",
            "Train Epoch: 0 [9600/50000 (19%)]\tLoss: 2.122483\n",
            "Train Epoch: 0 [10240/50000 (20%)]\tLoss: 1.833223\n",
            "Train Epoch: 0 [10880/50000 (22%)]\tLoss: 1.834156\n",
            "Train Epoch: 0 [11520/50000 (23%)]\tLoss: 1.865578\n",
            "Train Epoch: 0 [12160/50000 (24%)]\tLoss: 1.835891\n",
            "Train Epoch: 0 [12800/50000 (26%)]\tLoss: 1.792516\n",
            "Train Epoch: 0 [13440/50000 (27%)]\tLoss: 1.769741\n",
            "Train Epoch: 0 [14080/50000 (28%)]\tLoss: 1.924083\n",
            "Train Epoch: 0 [14720/50000 (29%)]\tLoss: 1.966536\n",
            "Train Epoch: 0 [15360/50000 (31%)]\tLoss: 1.738943\n",
            "Train Epoch: 0 [16000/50000 (32%)]\tLoss: 1.711061\n",
            "Train Epoch: 0 [16640/50000 (33%)]\tLoss: 1.872637\n",
            "Train Epoch: 0 [17280/50000 (35%)]\tLoss: 1.734414\n",
            "Train Epoch: 0 [17920/50000 (36%)]\tLoss: 1.643567\n",
            "Train Epoch: 0 [18560/50000 (37%)]\tLoss: 1.746627\n",
            "Train Epoch: 0 [19200/50000 (38%)]\tLoss: 1.662024\n",
            "Train Epoch: 0 [19840/50000 (40%)]\tLoss: 1.625201\n",
            "Train Epoch: 0 [20480/50000 (41%)]\tLoss: 1.866008\n",
            "Train Epoch: 0 [21120/50000 (42%)]\tLoss: 1.724853\n",
            "Train Epoch: 0 [21760/50000 (43%)]\tLoss: 1.698105\n",
            "Train Epoch: 0 [22400/50000 (45%)]\tLoss: 1.654916\n",
            "Train Epoch: 0 [23040/50000 (46%)]\tLoss: 1.662218\n",
            "Train Epoch: 0 [23680/50000 (47%)]\tLoss: 1.780622\n",
            "Train Epoch: 0 [24320/50000 (49%)]\tLoss: 1.781129\n",
            "Train Epoch: 0 [24960/50000 (50%)]\tLoss: 1.731494\n",
            "Train Epoch: 0 [25600/50000 (51%)]\tLoss: 1.904846\n",
            "Train Epoch: 0 [26240/50000 (52%)]\tLoss: 1.890113\n",
            "Train Epoch: 0 [26880/50000 (54%)]\tLoss: 1.634272\n",
            "Train Epoch: 0 [27520/50000 (55%)]\tLoss: 1.662629\n",
            "Train Epoch: 0 [28160/50000 (56%)]\tLoss: 1.604624\n",
            "Train Epoch: 0 [28800/50000 (58%)]\tLoss: 1.394887\n",
            "Train Epoch: 0 [29440/50000 (59%)]\tLoss: 1.812419\n",
            "Train Epoch: 0 [30080/50000 (60%)]\tLoss: 1.637410\n",
            "Train Epoch: 0 [30720/50000 (61%)]\tLoss: 1.555940\n",
            "Train Epoch: 0 [31360/50000 (63%)]\tLoss: 1.569589\n",
            "Train Epoch: 0 [32000/50000 (64%)]\tLoss: 1.533218\n",
            "Train Epoch: 0 [32640/50000 (65%)]\tLoss: 1.647764\n",
            "Train Epoch: 0 [33280/50000 (66%)]\tLoss: 1.758760\n",
            "Train Epoch: 0 [33920/50000 (68%)]\tLoss: 1.550635\n",
            "Train Epoch: 0 [34560/50000 (69%)]\tLoss: 1.830768\n",
            "Train Epoch: 0 [35200/50000 (70%)]\tLoss: 1.926887\n",
            "Train Epoch: 0 [35840/50000 (72%)]\tLoss: 1.790642\n",
            "Train Epoch: 0 [36480/50000 (73%)]\tLoss: 1.776731\n",
            "Train Epoch: 0 [37120/50000 (74%)]\tLoss: 1.665667\n",
            "Train Epoch: 0 [37760/50000 (75%)]\tLoss: 1.642655\n",
            "Train Epoch: 0 [38400/50000 (77%)]\tLoss: 1.597009\n",
            "Train Epoch: 0 [39040/50000 (78%)]\tLoss: 1.645024\n",
            "Train Epoch: 0 [39680/50000 (79%)]\tLoss: 1.266470\n",
            "Train Epoch: 0 [40320/50000 (81%)]\tLoss: 1.739606\n",
            "Train Epoch: 0 [40960/50000 (82%)]\tLoss: 1.497423\n",
            "Train Epoch: 0 [41600/50000 (83%)]\tLoss: 1.789076\n",
            "Train Epoch: 0 [42240/50000 (84%)]\tLoss: 1.584119\n",
            "Train Epoch: 0 [42880/50000 (86%)]\tLoss: 1.659987\n",
            "Train Epoch: 0 [43520/50000 (87%)]\tLoss: 1.511210\n",
            "Train Epoch: 0 [44160/50000 (88%)]\tLoss: 1.794776\n",
            "Train Epoch: 0 [44800/50000 (90%)]\tLoss: 1.523895\n",
            "Train Epoch: 0 [45440/50000 (91%)]\tLoss: 1.535004\n",
            "Train Epoch: 0 [46080/50000 (92%)]\tLoss: 1.633560\n",
            "Train Epoch: 0 [46720/50000 (93%)]\tLoss: 1.551598\n",
            "Train Epoch: 0 [47360/50000 (95%)]\tLoss: 1.686136\n",
            "Train Epoch: 0 [48000/50000 (96%)]\tLoss: 1.262411\n",
            "Train Epoch: 0 [48640/50000 (97%)]\tLoss: 1.418152\n",
            "Train Epoch: 0 [49280/50000 (98%)]\tLoss: 1.868970\n",
            "Train Epoch: 0 [49920/50000 (100%)]\tLoss: 1.622313\n",
            "Train Epoch: 1 [0/50000 (0%)]\tLoss: 1.550320\n",
            "Train Epoch: 1 [640/50000 (1%)]\tLoss: 1.414665\n",
            "Train Epoch: 1 [1280/50000 (3%)]\tLoss: 1.438024\n",
            "Train Epoch: 1 [1920/50000 (4%)]\tLoss: 1.361176\n",
            "Train Epoch: 1 [2560/50000 (5%)]\tLoss: 1.629406\n",
            "Train Epoch: 1 [3200/50000 (6%)]\tLoss: 1.649684\n",
            "Train Epoch: 1 [3840/50000 (8%)]\tLoss: 1.567068\n",
            "Train Epoch: 1 [4480/50000 (9%)]\tLoss: 1.465314\n",
            "Train Epoch: 1 [5120/50000 (10%)]\tLoss: 1.430813\n",
            "Train Epoch: 1 [5760/50000 (12%)]\tLoss: 1.419303\n",
            "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 1.306471\n",
            "Train Epoch: 1 [7040/50000 (14%)]\tLoss: 1.581740\n",
            "Train Epoch: 1 [7680/50000 (15%)]\tLoss: 1.590557\n",
            "Train Epoch: 1 [8320/50000 (17%)]\tLoss: 1.428307\n",
            "Train Epoch: 1 [8960/50000 (18%)]\tLoss: 1.365153\n",
            "Train Epoch: 1 [9600/50000 (19%)]\tLoss: 1.653833\n",
            "Train Epoch: 1 [10240/50000 (20%)]\tLoss: 1.603421\n",
            "Train Epoch: 1 [10880/50000 (22%)]\tLoss: 1.494860\n",
            "Train Epoch: 1 [11520/50000 (23%)]\tLoss: 1.534487\n",
            "Train Epoch: 1 [12160/50000 (24%)]\tLoss: 1.371576\n",
            "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 1.779967\n",
            "Train Epoch: 1 [13440/50000 (27%)]\tLoss: 1.465986\n",
            "Train Epoch: 1 [14080/50000 (28%)]\tLoss: 1.606772\n",
            "Train Epoch: 1 [14720/50000 (29%)]\tLoss: 1.652909\n",
            "Train Epoch: 1 [15360/50000 (31%)]\tLoss: 1.516294\n",
            "Train Epoch: 1 [16000/50000 (32%)]\tLoss: 1.489733\n",
            "Train Epoch: 1 [16640/50000 (33%)]\tLoss: 1.532951\n",
            "Train Epoch: 1 [17280/50000 (35%)]\tLoss: 1.493588\n",
            "Train Epoch: 1 [17920/50000 (36%)]\tLoss: 1.303767\n",
            "Train Epoch: 1 [18560/50000 (37%)]\tLoss: 1.429809\n",
            "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 1.279496\n",
            "Train Epoch: 1 [19840/50000 (40%)]\tLoss: 1.440534\n",
            "Train Epoch: 1 [20480/50000 (41%)]\tLoss: 1.668756\n",
            "Train Epoch: 1 [21120/50000 (42%)]\tLoss: 1.678245\n",
            "Train Epoch: 1 [21760/50000 (43%)]\tLoss: 1.611917\n",
            "Train Epoch: 1 [22400/50000 (45%)]\tLoss: 1.462741\n",
            "Train Epoch: 1 [23040/50000 (46%)]\tLoss: 1.329611\n",
            "Train Epoch: 1 [23680/50000 (47%)]\tLoss: 1.494522\n",
            "Train Epoch: 1 [24320/50000 (49%)]\tLoss: 1.455833\n",
            "Train Epoch: 1 [24960/50000 (50%)]\tLoss: 1.501258\n",
            "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.832764\n",
            "Train Epoch: 1 [26240/50000 (52%)]\tLoss: 1.398269\n",
            "Train Epoch: 1 [26880/50000 (54%)]\tLoss: 1.447373\n",
            "Train Epoch: 1 [27520/50000 (55%)]\tLoss: 1.533726\n",
            "Train Epoch: 1 [28160/50000 (56%)]\tLoss: 1.409787\n",
            "Train Epoch: 1 [28800/50000 (58%)]\tLoss: 1.589702\n",
            "Train Epoch: 1 [29440/50000 (59%)]\tLoss: 1.573849\n",
            "Train Epoch: 1 [30080/50000 (60%)]\tLoss: 1.375457\n",
            "Train Epoch: 1 [30720/50000 (61%)]\tLoss: 1.423677\n",
            "Train Epoch: 1 [31360/50000 (63%)]\tLoss: 1.565675\n",
            "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 1.326763\n",
            "Train Epoch: 1 [32640/50000 (65%)]\tLoss: 1.521485\n",
            "Train Epoch: 1 [33280/50000 (66%)]\tLoss: 1.443556\n",
            "Train Epoch: 1 [33920/50000 (68%)]\tLoss: 1.480243\n",
            "Train Epoch: 1 [34560/50000 (69%)]\tLoss: 1.517608\n",
            "Train Epoch: 1 [35200/50000 (70%)]\tLoss: 1.691588\n",
            "Train Epoch: 1 [35840/50000 (72%)]\tLoss: 1.175961\n",
            "Train Epoch: 1 [36480/50000 (73%)]\tLoss: 1.461297\n",
            "Train Epoch: 1 [37120/50000 (74%)]\tLoss: 1.403233\n",
            "Train Epoch: 1 [37760/50000 (75%)]\tLoss: 1.498647\n",
            "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.621450\n",
            "Train Epoch: 1 [39040/50000 (78%)]\tLoss: 1.333021\n",
            "Train Epoch: 1 [39680/50000 (79%)]\tLoss: 1.460640\n",
            "Train Epoch: 1 [40320/50000 (81%)]\tLoss: 1.639763\n",
            "Train Epoch: 1 [40960/50000 (82%)]\tLoss: 1.382468\n",
            "Train Epoch: 1 [41600/50000 (83%)]\tLoss: 1.385041\n",
            "Train Epoch: 1 [42240/50000 (84%)]\tLoss: 1.413155\n",
            "Train Epoch: 1 [42880/50000 (86%)]\tLoss: 1.344909\n",
            "Train Epoch: 1 [43520/50000 (87%)]\tLoss: 1.390315\n",
            "Train Epoch: 1 [44160/50000 (88%)]\tLoss: 1.219540\n",
            "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 1.426042\n",
            "Train Epoch: 1 [45440/50000 (91%)]\tLoss: 1.542807\n",
            "Train Epoch: 1 [46080/50000 (92%)]\tLoss: 1.588271\n",
            "Train Epoch: 1 [46720/50000 (93%)]\tLoss: 1.436571\n",
            "Train Epoch: 1 [47360/50000 (95%)]\tLoss: 1.324274\n",
            "Train Epoch: 1 [48000/50000 (96%)]\tLoss: 1.624387\n",
            "Train Epoch: 1 [48640/50000 (97%)]\tLoss: 1.456227\n",
            "Train Epoch: 1 [49280/50000 (98%)]\tLoss: 1.281420\n",
            "Train Epoch: 1 [49920/50000 (100%)]\tLoss: 1.454489\n",
            "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.306105\n",
            "Train Epoch: 2 [640/50000 (1%)]\tLoss: 1.487033\n",
            "Train Epoch: 2 [1280/50000 (3%)]\tLoss: 1.330808\n",
            "Train Epoch: 2 [1920/50000 (4%)]\tLoss: 1.476644\n",
            "Train Epoch: 2 [2560/50000 (5%)]\tLoss: 1.459222\n",
            "Train Epoch: 2 [3200/50000 (6%)]\tLoss: 1.175154\n",
            "Train Epoch: 2 [3840/50000 (8%)]\tLoss: 1.511406\n",
            "Train Epoch: 2 [4480/50000 (9%)]\tLoss: 1.342914\n",
            "Train Epoch: 2 [5120/50000 (10%)]\tLoss: 1.654419\n",
            "Train Epoch: 2 [5760/50000 (12%)]\tLoss: 1.201881\n",
            "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 1.520277\n",
            "Train Epoch: 2 [7040/50000 (14%)]\tLoss: 1.502313\n",
            "Train Epoch: 2 [7680/50000 (15%)]\tLoss: 1.247556\n",
            "Train Epoch: 2 [8320/50000 (17%)]\tLoss: 1.380391\n",
            "Train Epoch: 2 [8960/50000 (18%)]\tLoss: 1.404667\n",
            "Train Epoch: 2 [9600/50000 (19%)]\tLoss: 1.451973\n",
            "Train Epoch: 2 [10240/50000 (20%)]\tLoss: 1.466834\n",
            "Train Epoch: 2 [10880/50000 (22%)]\tLoss: 1.381749\n",
            "Train Epoch: 2 [11520/50000 (23%)]\tLoss: 1.493728\n",
            "Train Epoch: 2 [12160/50000 (24%)]\tLoss: 1.434840\n",
            "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.171516\n",
            "Train Epoch: 2 [13440/50000 (27%)]\tLoss: 1.354316\n",
            "Train Epoch: 2 [14080/50000 (28%)]\tLoss: 1.183628\n",
            "Train Epoch: 2 [14720/50000 (29%)]\tLoss: 1.330933\n",
            "Train Epoch: 2 [15360/50000 (31%)]\tLoss: 1.144628\n",
            "Train Epoch: 2 [16000/50000 (32%)]\tLoss: 1.372331\n",
            "Train Epoch: 2 [16640/50000 (33%)]\tLoss: 1.250035\n",
            "Train Epoch: 2 [17280/50000 (35%)]\tLoss: 1.368291\n",
            "Train Epoch: 2 [17920/50000 (36%)]\tLoss: 1.324278\n",
            "Train Epoch: 2 [18560/50000 (37%)]\tLoss: 1.106035\n",
            "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 1.142743\n",
            "Train Epoch: 2 [19840/50000 (40%)]\tLoss: 1.271293\n",
            "Train Epoch: 2 [20480/50000 (41%)]\tLoss: 1.173500\n",
            "Train Epoch: 2 [21120/50000 (42%)]\tLoss: 1.478015\n",
            "Train Epoch: 2 [21760/50000 (43%)]\tLoss: 1.701514\n",
            "Train Epoch: 2 [22400/50000 (45%)]\tLoss: 1.512814\n",
            "Train Epoch: 2 [23040/50000 (46%)]\tLoss: 1.393045\n",
            "Train Epoch: 2 [23680/50000 (47%)]\tLoss: 1.333002\n",
            "Train Epoch: 2 [24320/50000 (49%)]\tLoss: 1.522033\n",
            "Train Epoch: 2 [24960/50000 (50%)]\tLoss: 1.267573\n",
            "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.502502\n",
            "Train Epoch: 2 [26240/50000 (52%)]\tLoss: 1.457965\n",
            "Train Epoch: 2 [26880/50000 (54%)]\tLoss: 1.455220\n",
            "Train Epoch: 2 [27520/50000 (55%)]\tLoss: 1.301336\n",
            "Train Epoch: 2 [28160/50000 (56%)]\tLoss: 1.335807\n",
            "Train Epoch: 2 [28800/50000 (58%)]\tLoss: 1.289125\n",
            "Train Epoch: 2 [29440/50000 (59%)]\tLoss: 1.236415\n",
            "Train Epoch: 2 [30080/50000 (60%)]\tLoss: 1.331383\n",
            "Train Epoch: 2 [30720/50000 (61%)]\tLoss: 1.131726\n",
            "Train Epoch: 2 [31360/50000 (63%)]\tLoss: 1.125545\n",
            "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 1.248167\n",
            "Train Epoch: 2 [32640/50000 (65%)]\tLoss: 1.469165\n",
            "Train Epoch: 2 [33280/50000 (66%)]\tLoss: 1.623211\n",
            "Train Epoch: 2 [33920/50000 (68%)]\tLoss: 1.200734\n",
            "Train Epoch: 2 [34560/50000 (69%)]\tLoss: 1.141317\n",
            "Train Epoch: 2 [35200/50000 (70%)]\tLoss: 1.378973\n",
            "Train Epoch: 2 [35840/50000 (72%)]\tLoss: 1.382892\n",
            "Train Epoch: 2 [36480/50000 (73%)]\tLoss: 1.444086\n",
            "Train Epoch: 2 [37120/50000 (74%)]\tLoss: 1.339971\n",
            "Train Epoch: 2 [37760/50000 (75%)]\tLoss: 1.495552\n",
            "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.348649\n",
            "Train Epoch: 2 [39040/50000 (78%)]\tLoss: 1.245532\n",
            "Train Epoch: 2 [39680/50000 (79%)]\tLoss: 1.435589\n",
            "Train Epoch: 2 [40320/50000 (81%)]\tLoss: 1.444153\n",
            "Train Epoch: 2 [40960/50000 (82%)]\tLoss: 1.402653\n",
            "Train Epoch: 2 [41600/50000 (83%)]\tLoss: 1.209595\n",
            "Train Epoch: 2 [42240/50000 (84%)]\tLoss: 1.384278\n",
            "Train Epoch: 2 [42880/50000 (86%)]\tLoss: 1.387765\n",
            "Train Epoch: 2 [43520/50000 (87%)]\tLoss: 1.294079\n",
            "Train Epoch: 2 [44160/50000 (88%)]\tLoss: 1.317077\n",
            "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 1.336535\n",
            "Train Epoch: 2 [45440/50000 (91%)]\tLoss: 1.186762\n",
            "Train Epoch: 2 [46080/50000 (92%)]\tLoss: 1.193766\n",
            "Train Epoch: 2 [46720/50000 (93%)]\tLoss: 1.731924\n",
            "Train Epoch: 2 [47360/50000 (95%)]\tLoss: 1.220863\n",
            "Train Epoch: 2 [48000/50000 (96%)]\tLoss: 1.335109\n",
            "Train Epoch: 2 [48640/50000 (97%)]\tLoss: 1.127456\n",
            "Train Epoch: 2 [49280/50000 (98%)]\tLoss: 1.217561\n",
            "Train Epoch: 2 [49920/50000 (100%)]\tLoss: 1.179910\n",
            "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.219532\n",
            "Train Epoch: 3 [640/50000 (1%)]\tLoss: 1.153630\n",
            "Train Epoch: 3 [1280/50000 (3%)]\tLoss: 1.456079\n",
            "Train Epoch: 3 [1920/50000 (4%)]\tLoss: 1.102099\n",
            "Train Epoch: 3 [2560/50000 (5%)]\tLoss: 1.504650\n",
            "Train Epoch: 3 [3200/50000 (6%)]\tLoss: 1.340590\n",
            "Train Epoch: 3 [3840/50000 (8%)]\tLoss: 1.355372\n",
            "Train Epoch: 3 [4480/50000 (9%)]\tLoss: 1.187619\n",
            "Train Epoch: 3 [5120/50000 (10%)]\tLoss: 1.370970\n",
            "Train Epoch: 3 [5760/50000 (12%)]\tLoss: 1.101350\n",
            "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 1.143108\n",
            "Train Epoch: 3 [7040/50000 (14%)]\tLoss: 1.190517\n",
            "Train Epoch: 3 [7680/50000 (15%)]\tLoss: 1.486432\n",
            "Train Epoch: 3 [8320/50000 (17%)]\tLoss: 1.308033\n",
            "Train Epoch: 3 [8960/50000 (18%)]\tLoss: 1.308743\n",
            "Train Epoch: 3 [9600/50000 (19%)]\tLoss: 1.200017\n",
            "Train Epoch: 3 [10240/50000 (20%)]\tLoss: 1.267832\n",
            "Train Epoch: 3 [10880/50000 (22%)]\tLoss: 1.131933\n",
            "Train Epoch: 3 [11520/50000 (23%)]\tLoss: 1.471042\n",
            "Train Epoch: 3 [12160/50000 (24%)]\tLoss: 1.392337\n",
            "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 1.421166\n",
            "Train Epoch: 3 [13440/50000 (27%)]\tLoss: 1.235034\n",
            "Train Epoch: 3 [14080/50000 (28%)]\tLoss: 1.500160\n",
            "Train Epoch: 3 [14720/50000 (29%)]\tLoss: 1.008471\n",
            "Train Epoch: 3 [15360/50000 (31%)]\tLoss: 1.079076\n",
            "Train Epoch: 3 [16000/50000 (32%)]\tLoss: 1.254693\n",
            "Train Epoch: 3 [16640/50000 (33%)]\tLoss: 1.324364\n",
            "Train Epoch: 3 [17280/50000 (35%)]\tLoss: 1.181418\n",
            "Train Epoch: 3 [17920/50000 (36%)]\tLoss: 1.077037\n",
            "Train Epoch: 3 [18560/50000 (37%)]\tLoss: 1.383124\n",
            "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 1.243842\n",
            "Train Epoch: 3 [19840/50000 (40%)]\tLoss: 1.274696\n",
            "Train Epoch: 3 [20480/50000 (41%)]\tLoss: 0.973197\n",
            "Train Epoch: 3 [21120/50000 (42%)]\tLoss: 1.330801\n",
            "Train Epoch: 3 [21760/50000 (43%)]\tLoss: 1.419053\n",
            "Train Epoch: 3 [22400/50000 (45%)]\tLoss: 1.280363\n",
            "Train Epoch: 3 [23040/50000 (46%)]\tLoss: 1.227796\n",
            "Train Epoch: 3 [23680/50000 (47%)]\tLoss: 1.389950\n",
            "Train Epoch: 3 [24320/50000 (49%)]\tLoss: 1.206035\n",
            "Train Epoch: 3 [24960/50000 (50%)]\tLoss: 1.333972\n",
            "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.369266\n",
            "Train Epoch: 3 [26240/50000 (52%)]\tLoss: 1.268191\n",
            "Train Epoch: 3 [26880/50000 (54%)]\tLoss: 1.115850\n",
            "Train Epoch: 3 [27520/50000 (55%)]\tLoss: 1.248903\n",
            "Train Epoch: 3 [28160/50000 (56%)]\tLoss: 1.311414\n",
            "Train Epoch: 3 [28800/50000 (58%)]\tLoss: 1.198035\n",
            "Train Epoch: 3 [29440/50000 (59%)]\tLoss: 1.369832\n",
            "Train Epoch: 3 [30080/50000 (60%)]\tLoss: 1.069650\n",
            "Train Epoch: 3 [30720/50000 (61%)]\tLoss: 1.048166\n",
            "Train Epoch: 3 [31360/50000 (63%)]\tLoss: 1.201653\n",
            "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 1.285244\n",
            "Train Epoch: 3 [32640/50000 (65%)]\tLoss: 1.211361\n",
            "Train Epoch: 3 [33280/50000 (66%)]\tLoss: 1.258096\n",
            "Train Epoch: 3 [33920/50000 (68%)]\tLoss: 1.103859\n",
            "Train Epoch: 3 [34560/50000 (69%)]\tLoss: 1.177925\n",
            "Train Epoch: 3 [35200/50000 (70%)]\tLoss: 1.360536\n",
            "Train Epoch: 3 [35840/50000 (72%)]\tLoss: 1.509653\n",
            "Train Epoch: 3 [36480/50000 (73%)]\tLoss: 1.273276\n",
            "Train Epoch: 3 [37120/50000 (74%)]\tLoss: 1.465193\n",
            "Train Epoch: 3 [37760/50000 (75%)]\tLoss: 1.110343\n",
            "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 1.390739\n",
            "Train Epoch: 3 [39040/50000 (78%)]\tLoss: 1.637758\n",
            "Train Epoch: 3 [39680/50000 (79%)]\tLoss: 1.394281\n",
            "Train Epoch: 3 [40320/50000 (81%)]\tLoss: 1.524115\n",
            "Train Epoch: 3 [40960/50000 (82%)]\tLoss: 1.209424\n",
            "Train Epoch: 3 [41600/50000 (83%)]\tLoss: 1.108045\n",
            "Train Epoch: 3 [42240/50000 (84%)]\tLoss: 1.158533\n",
            "Train Epoch: 3 [42880/50000 (86%)]\tLoss: 1.629228\n",
            "Train Epoch: 3 [43520/50000 (87%)]\tLoss: 1.283777\n",
            "Train Epoch: 3 [44160/50000 (88%)]\tLoss: 1.414493\n",
            "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 1.369584\n",
            "Train Epoch: 3 [45440/50000 (91%)]\tLoss: 1.123334\n",
            "Train Epoch: 3 [46080/50000 (92%)]\tLoss: 1.338443\n",
            "Train Epoch: 3 [46720/50000 (93%)]\tLoss: 0.976520\n",
            "Train Epoch: 3 [47360/50000 (95%)]\tLoss: 1.183399\n",
            "Train Epoch: 3 [48000/50000 (96%)]\tLoss: 1.031677\n",
            "Train Epoch: 3 [48640/50000 (97%)]\tLoss: 1.471247\n",
            "Train Epoch: 3 [49280/50000 (98%)]\tLoss: 1.337953\n",
            "Train Epoch: 3 [49920/50000 (100%)]\tLoss: 1.229582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model #= Net()\n",
        "#Model=model\n",
        "model.load_state_dict(torch.load('model.pth'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUjrJZpJ6jAV",
        "outputId": "a39c12aa-786f-45e8-d864-34d53d99e04c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "test = x_test[50].reshape(1,3,32,32)\n",
        "print(y_test[50])\n",
        "test.shape\n",
        "print(torch.argmax(model(test),dim=1))#.dtype)\n",
        "plt.imshow(test.to(torch.uint8).numpy().reshape(32,32,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "YAHahUTtGGPP",
        "outputId": "33df9e1e-9180-40c0-cbde-a5037820c504"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([9], dtype=torch.uint8)\n",
            "tensor([9])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f03dfef3450>"
            ]
          },
          "metadata": {},
          "execution_count": 225
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "torch.argmax(model(test),dim=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_lrvuGwGNvX",
        "outputId": "8949704c-0ebd-4f8e-98e8-1bd6298ccd06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1])"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.imshow(test.to(torch.uint8).numpy().reshape(32,32,3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "D8uXuaB6J3SU",
        "outputId": "3b91fd3e-6606-49f1-9dc7-8d764daefdc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f03e204dad0>"
            ]
          },
          "metadata": {},
          "execution_count": 155
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Fb6Ho9oL-0j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}